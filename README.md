PS. Те замечния по коду и архитектуре скрипта пока не исправил и не дорааботал (можно не смотреть) начну деалть следом (почитал идейно сам скрипт сиьлно поменяться не должен ) пока лишь собрал в кучу все добивл блок анализа данных он тоже лежит в репозитории в блоке буде на него ссыылкаа как и на визуализаию, также прописал методологию и струкктуру общего проектаб также пока не могу нормально добавить тетрадку тк она много весит а в пдф есть сложности с переносом изза библитеки plotly, пока просто прикрепляю ссылку но тот кто хочеет прочитать должен скачать
# WB_data_analisys
## Содержание
- [Цель и задачи](#title1)
- [Сбор и подготовка данных](#title2)
- [Анализ данных](#title3)
  - [Анализ данных в python](#title3.1)
  - [Анализ данных в BI](#title3.2)
## <a id="title1">Цель и задачи</a>
**Цель**

Целью данного исследования является комплексный анализ факторов, связанных с ожидаемой продолжительностью жизни населения в странах мира, а также выявление устойчивых социально-экономических, демографических и структурных различий между странами на разных этапах развития.

**Задачи**

- Парсинг данных API [World Bank](https://www.worldbank.org/ext/en/home)
- Обработка и нормализция полученных данных
- Организация хранилища для нормализоованных данных (облачная СУБД Postgresql [Supabase](https://supabase.com/))
- Подготовка витрин данных для BI системы
- Разведочный и структурный анализ (Python)
- Динамический анализ данных (Yandex Datalens)

**Итог**

Релизован ETL пайплайн, которые парсит данныые по API WB, обрабаытвает и нормализует их, и выгружает в развернутую облачную СУБД Postgres (Supabase). [Дашборд в Yandex Datalens](https://datalens.ru/l58lqbi9o6em5), который подключается к нашей CУБД, и берет за основу специально подготовеные [витрины данных](https://github.com/ososovyan/WB_data_analisys/blob/main/vew_preaparation.sql). И отдельно [разведочный и структурный в Python](https://github.com/ososovyan/WB_data_analisys/blob/main/analys.ipynb)

**Стек**

ETL pipline : Python, requests, pandas, numpy, re, json, psycopg2 

Анализ данных : Jupyter Notebook, Python, pandas, matplotlib, seeaborn, plotly, sklearn, scipy, sqlalchemy (для подключения к БД)

BI: Postgresql, Yandex Datalens

## <a id="title2">Сбор и подготовка данных</a>
Сбор, обработка и загрузка данных осущетсвлена по логике ETL: процесс Extract – Transform – Load.
На вход наш скрипт получает `config.json` с параметрами подключения к API WB, а также параметрами для подключения к СУБД Postgresql.
Также наш скрипт осуществляет логирование

**0. Загрузка конфигурации**
Наш скрипт загружает данные конфигурцаии из файла, затем идет блок валидации данных полученных из этого файла, алгоритм валидации делает подключение к API болле робастным (отработка возможных ошибок, легких опечаток не нарушает работу скрипта, также выявление нарушения структуры или наличия ошибок можно отследить в log файле)

**1. Extract**

Данная часть отвечает за загрузку данных с APi. Мы используем библитоеку request для подключения к API. Релизована ассинхронная retry-логика: некоторые ошибки (неклиентсике) не останавливают процесс, происходит попытка переподключения (кол-во можно регулировать в config). Также релизована логика обработки пагинцаии. Обе функции универсаальны и подходят для работы с любыми API. Реализована отдельная функция, которая обрабатывает данные configa и создает настройки для подключения к API WB.

**2. Transform**

Данный блок посвящен обработке полученных данных их нормализации. В этом блоке мы приводим `json -> pandas`. Коллонки полученного датфрейма приводим к `snake_case`, убюираем лишние колонки (вложеные структуры). Мы ожидаем увидеть определенную структуру, поэтому на данныом этапе производим создание справочных таблиц, для организации в БД и оптимизации памяти, а также стандартизируем вид возмонжных pk и fk и названия справочных таблиц, для этго используем регулярные выражения (библитека re). 

**3. Load**

Данный блок посвящен работе с СУБД. На данном этапе создавется подключение к БД: c помощью библитеки psycopg2 мы создаем подключение к БД (параметры для подключения мы получем из валидированного config). Далее пред тем как выполнить основной запрос, мы проверяем наличие справочных таблиц, обновляем их, если их не существует - создаем.      

![Схема хранения данных](https://github.com/ososovyan/WB_data_analisys/blob/main/Scema_bd.png) 

На рисунке представдленая схема хранения данных (тип снежинка). Если справочных таблиц нет - мы идем в обратном порядке уровня. Мы создаем таблицу проверяем каакие таблицы уже существуют и по ожидаемому имени таблице, имени pk и fk автоматичсеки устанавливае связи внутри (Это происходило автоматически для каждой таблицы за счет функции, которая использует динамические sql запросы в зависмости от срдержимого pd.df. Функция универсальна не привязана к конкретной архитктуре, ограничена лишь логикой нейминга таблиц и ключей. Если таблица сущетсвует мы лишь обновляем и дописыываем содержимое pd.df.

## <a id="title3">Анализ данных</a>

Анализ полученных данных можно условно разделить на два этапа: [разведочный и структурный анализ в python](https://github.com/ososovyan/WB_data_analisys/blob/main/analys.ipynb), [анализ динамики в BI системе](https://datalens.ru/l58lqbi9o6em5). В первую очередь разделение обусловлено удобством и раными целями. Цель первого (основная для данной работы) - комплексный анализ факторов, связанных с ожидаемой продолжительностью жизни населения в странах мира, а также выявление устойчивых социально-экономических, демографических и структурных различий между странами на разных этапах развития. Цель второго скорее почва для дальнейшего исследования связей в динамике времени для более детального изучения трендов во времени (для конкретных стран)

Главный показатель в моем иследовани продолжительность жизни SP.DYN.LE00.IN
Диапазон 1960:2024
Код WB             Показатель WB                                   
- SP.DYN.CBRT.IN     Рождаемость (кол-во рождений на 1000 человек)
- SP.DYN.CDRT.IN     Смертность (кол-во смертей на 1000 человек)
- SP.POP.GROW        Рост населения (%)
- SP.DYN.IMRT.IN     Детская смертность (0–1 год)
- NY.GDP.PCAP.CD     ВВП на душу населения (долл. США, номинал)      
- NE.TRD.GNFS.ZS     Торговля (% ВВП)
- EG.USE.PCAP.KG.OE  Энергопотребление на душу (кг нефт. экв.)
- NV.AGR.TOTL.ZS     Сельское хозяйство (% ВВП)
- NV.IND.TOTL.ZS     Промышленность (% ВВП)
- SP.URB.TOTL.IN.ZS  Урбанизация (% населения)
- SE.XPD.TOTL.GD.ZS расходы на образование

Данные показатели из разных груп: демографические, экономические, социальные - чтобы максимально затронуть все аспекты жизни общества

### <a id="title3.1">Анализ данных в Python</a>

**Подключение к БД**

С помощью библитеки sqlalchemy извлекаем данные всех таблиц из нашей БД

**Знакомство с данными**

Данный этап по большей части направлен на анализ значений показатеелей (обработку пропусков), были попытки найти закономерности пропусков (самы грязные ииндикаторы, страны, за счет чего в целом образуется столько пропусков) и выбора стратегии заполнения пропусков

Как рузльтат были выявлены индикаторы, годы и страны, которые лучше исключить из анализа ввиду остуствия или неполноты данных. Также центральные пропуски были заполнены линейной интреполяцией, левые и правые уровнем последнего известного индикатора

**Разведочный анализ**

Далее в разрезе каждого индикатора был проведен сепарированный разведочный анализ, чтобы найти выбросы, ошибки интреполяции, особенности и закономерности (в разрзе мира, категорий доходов стран, региона), также исследование равпределений данных

Как результат, нахолждение выбросов и экстремальных значений и выбор стратегии обработки таких знчений в дальнейшем

**Создание широкой панели**

Следующий этап создание широкой панели формата.
В резульате мы получили широкую таблицу, которую будем применять в дальнейшем анализе, для каждой страны и года есть значения каждого индикатора, обработанные, первоначальные, флаг 2 - данные некорректны либо их нет, 1 - экстремальное значение, 0 - все в порядке, это нормально что есть пропуски для значений показателей

**Анализ корреляции**

Была построена общая матрица корреляци и визуализированна с помощью библитоеки `seaborn` в виде тепловой карты (эта визуализация для понимания связей внутри показателей, нахождения мультиколлинеарности и выбора показатеей для адльнейшего анализа)

Таакже была построена матрица корреялции для показаьтеля продолжительность жзни с другими, общая, в разрезе регона, уровня дохода и в разрезе десятилетия (эта виизуализация, также необходима для выбора показателей для дальнейшего анализа, исследования трендов связей во времени и для исследования свзяей внутри структур)

Обе мвтрицы корреляции были построены на основе критерия Пирсона, однако есть показатели которые довольно шумные и разбросанные (например ВВП), для таких показаетлей ббыла построена матрица кореляций по критерию Спирмана (боллее робастен к выбросам и шумности)

Также били построены диаграмы рассеяния для продолжительности жиизни и остальных показателей

Результат выбор показателей, анализ закономерностей

**Структурный аанализ**

Ядро структурного анализа библитека `sklearn`

Для более глубокого анализа была построена карта (библитока `plotly`) по годам для показателя продолжиткельности жизни, а такеж даиграмы рассеяния по годам для исследования трендов во времени
В раамках дальнейшго исследоваяни использовались агрегировннае данные за современный период 2010-2023 для избежания сильного влияния временных трендов

*PCA*

PCA (анализ главных компонент) с целью выявления скрытыых структур многомерных даных и оценки степени совместной вариации ключевых социально-экономических и демографических показателей. PCA используется больше для диагностики и описания, который предшествует кластерному анализу.

Перед применением PCA все переменные были стандартизированы, поскольку метод чувствителен к масштабу измерения (методы `StandardScaler`,  `PCA` библитеки `sklearn`)

*Кластерный анализ*

Джалее, на основе выбранных показателей мы провели кластеризациюю стран методом K-means. Метод хорошо масштабируется на большое число стран и позволяет получить устойчивые и наглядные кластеры, которые удобно использовать для последующего сравнения уровней ожидаемой продолжительности жизни. Кол-во кластеров мы выбрали с помощью сравнения метода локтя и метода оценки качетсва кластеров (`KMeans`,  `silhouette_score` библитеки `sklearn`) оптимальныым стало число 3. Также для подбора центров кластеров использовали метод `k-means++` c улучшенной инициализацие центров, выбираем лучшую из 10 кластеризаций.

Результат разделение стран на три категории (которые условно можно охарактеризовать как развитиы, средниие, имеющие низкий уровнеь совокупного развития)

*Регресионный анализ*

Ядро регресии показатель продорлжительности жизни
В рамках этого блока была построена базовая линейная регрессия, а также линенйая реегресиия в разрезе кластеорв, для исследования силы влияния показателей на продолжительность жизни в разреезе клаастеров

*Статистические тесты*  

Нулевая гипотеза: Распределения показателя продолжительности жизни одинаковы для всех кластеров

Альтернативная гипотеза: Существует хотя бы один кластер отличающийся от остальных

Ввиду неоднородности распределений и наличия экстремальных значений был использован непараметрический тест Kruskal–Wallis. Он ранжирует данные всех групп, а затем сравнивает суммы рангов, чтобы определить, есть ли статистически значимые различия между группами. Это обобщение критерия Манна-Уитни для трех и более выборок, проверяющее нулевую гипотезу о равенстве медиан

Результаты теста Kruskal–Wallis показали, что все ключевые показатели статистически значимо различаются между выделенными кластерами. Это свидетельствует корректности кластеризации: выявленные группы стран являются структурно различными, а не результатом случайного разбиения данных
Это позволяет утверждать, что выявленные типы стран характеризуются принципиально различными социально-экономическими и демографическими условиями, что обосновывает использование диффференцированного подхода к анализу факторов продолжительности жизни

**Выводы**

Все заккаанчивается финальным блоком выводы. Более детально познакомится с анализом предлагаю по [ссылке](https://github.com/ososovyan/WB_data_analisys/blob/main/analys.ipynb)

### <a id="title3.2">Анализ данных в BI</a>

По скольку довольно много стран и показателей, для возможности индивидуального сравнения динамики разных показателей в разрезе разных стран за разные периоды, была создан [дашбордд](https://datalens.ru/l58lqbi9o6em5), для которого были созданы следующие представлния с помощью [sql запросоов](https://github.com/ososovyan/WB_data_analisys/blob/main/vew_preaparation.sql)

- `mv_main_table_proс`

Материлизованое представление интерполированных данных в sql, c подсчетом доа метрик (волаатильность, дельта). Также для оптимизации работы, для основных полей который подвергаются агргацции созданы индексы для оптимизации работы бд

- `v_global`, `v_region`, `v_income_level`

Обычные представления на основе, `mv_main_table_proс`, для аналииза динамики в разрезе мира, региона, уровня дохода (агрегированные таблицы по указанным группам)

- `v_country_rank`

Обычное представление для анализа лидеров и интилидиров, покаазателя, в разрезе года

**Дашбод**

Дащборд усолвно можно поделить на 5 частей: анализ общемировой динамики, анализ региональнй динамики, анализ динамики в разрезе уровня доходв, анализ динамики в раазрезе стран. Каждый из блоков содержит основу графикии трендов среднего, волатильности (по годам), для стран есть еще график дельты. В каждом разделе есть средние показатели - индикаторы. Релизована возможность строить множественныые графики внутри регионов, уровней доходов и стран (например можно выбрать одновременно пять стран вне зависимости от других признаков и провести сравнительный анализ динамики

Также для анализа в разрезе года построена карта и рейтинги по показателю за этот год.

[Отчет](https://datalens.ru/reports/ue5muhmqhfhse-analiz) по динамическому аналиизу таакже можно найти в datalens

